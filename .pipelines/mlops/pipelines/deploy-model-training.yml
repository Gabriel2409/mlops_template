# simulates an ETL process to create a new version of the datasets
# (here we just copy files from one place to another)
# Done with kedro-azureml using the compute cluster of the aml workspace.
# In a real scenario, would probably be done without using the wokspace compute cluster

variables:
  # - ${{ if eq(variables['Build.SourceBranchName'], 'main') }}:
  #     # 'main' branch: PRD environment
  #     - template: ../../config-infra-prod.yml
  # - ${{ if ne(variables['Build.SourceBranchName'], 'main') }}:
  #     # 'develop' or feature branches: DEV environment
  #     - template: ../../config-infra-dev.yml
  - template: ../../config-infra-prod.yml
  - name: kedro_pipeline_name # pipeline to launch to train the model
    value: tfidf_sgd_classifier
  - name: model_name # name to give to the output model
    value: mlops_category_classifier
  - name: model_node_name # node where the model is stored as output
    value: log_sklearn_scores

trigger:
  - none

pool:
  vmImage: $(ap_vm_image)

stages:
  - stage: TrainAndRegisterModel
    jobs:
      - job: TrainAndRegisterModel
        steps:
          - checkout: self
          - template: ../../templates/install-aml-cli.yml
          - template: ../../templates/connect-to-workspace.yml
          # todo: add unit test pipeline
          - template: ../../templates/install-and-cache-python-requirements.yml
          - template: ../../templates/launch-kedro-azureml-pipeline.yml
            parameters:
              kedro_pipeline_name: ${{ variables.kedro_pipeline_name }}
              capture_pipeline_name: true

          - task: PublishBuildArtifacts@1
            displayName: 'Publish Text File as Artifact'
            inputs:
              PathtoPublish: $(System.DefaultWorkingDirectory)/kedro_azureml_pipeline_infos.txt
              ArtifactName: 'MyPipelineInfos'

          - template: ../../templates/retrieve-kedro-job-name.yml
            parameters:
              parent_aml_pipeline_name: $(LaunchKedroPipeline.CapturedAmlPipelineName)
              job_display_name: ${{ variables.model_node_name }}
          - template: ../../templates/register-mlflow-model.yml
            parameters:
              job_name: $(RetrieveJobName.CapturedJobName)
              model_name: ${{ variables.model_name }}
          - script: |
              echo "Publishing asset name and version as artifacts..."
              echo "${{ variables.model_name }}" > $(Build.ArtifactStagingDirectory)/model_name.txt
              $model_version= $(az ml model list --name dummy_classifier  --query "[].{Version:version}" --output tsv | sort -r | head -n 1)
              echo "$model_version" >> $(Build.ArtifactStagingDirectory)/model_version.txt
          - task: PublishPipelineArtifact@1
            inputs:
              targetPath: '$(Build.ArtifactStagingDirectory)' # Publish the entire staging directory
              artifact: 'model_info' # Give a name to your artifact
